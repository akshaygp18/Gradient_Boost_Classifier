{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0af568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d1fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/shrikant-temburwar/Wine-Quality-Dataset/master/winequality-red.csv\",sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86944319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baa7deb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94ce03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "558b4f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b60425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.310596</td>\n",
       "      <td>0.529478</td>\n",
       "      <td>0.272333</td>\n",
       "      <td>2.523400</td>\n",
       "      <td>0.088124</td>\n",
       "      <td>15.893304</td>\n",
       "      <td>46.825975</td>\n",
       "      <td>0.996709</td>\n",
       "      <td>3.309787</td>\n",
       "      <td>0.658705</td>\n",
       "      <td>10.432315</td>\n",
       "      <td>5.623252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.736990</td>\n",
       "      <td>0.183031</td>\n",
       "      <td>0.195537</td>\n",
       "      <td>1.352314</td>\n",
       "      <td>0.049377</td>\n",
       "      <td>10.447270</td>\n",
       "      <td>33.408946</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.155036</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>1.082065</td>\n",
       "      <td>0.823578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.997820</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1359.000000       1359.000000  1359.000000     1359.000000   \n",
       "mean        8.310596          0.529478     0.272333        2.523400   \n",
       "std         1.736990          0.183031     0.195537        1.352314   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.430000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1359.000000          1359.000000           1359.000000  1359.000000   \n",
       "mean      0.088124            15.893304             46.825975     0.996709   \n",
       "std       0.049377            10.447270             33.408946     0.001869   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996700   \n",
       "75%       0.091000            21.000000             63.000000     0.997820   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1359.000000  1359.000000  1359.000000  1359.000000  \n",
       "mean      3.309787     0.658705    10.432315     5.623252  \n",
       "std       0.155036     0.170667     1.082065     0.823578  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1b01f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('quality',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b7ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "331be88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2da4fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4017243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74eb2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'loss':['logloss','deviance','exponential'],\n",
    "    'learning_rate':[0.1,0.01,0.02,0.2],\n",
    "    'n_estimators':[100,200,300,400],\n",
    "    'criterion':['friedman_mse','squared_error']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5184b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'learning_rate': [0.1, 0.01, 0.02, 0.2],\n",
       "                         'loss': ['logloss', 'deviance', 'exponential'],\n",
       "                         'n_estimators': [100, 200, 300, 400]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(estimator=classifier,param_grid=parameters,scoring='accuracy',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1db7c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.533 total time=   1.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.538 total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.577 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.566 total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.538 total time=   1.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.522 total time=   2.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.527 total time=   2.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.588 total time=   2.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.582 total time=   2.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.527 total time=   2.7s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.538 total time=   3.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.527 total time=   3.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.599 total time=   3.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.577 total time=   3.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.533 total time=   4.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.527 total time=   5.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.505 total time=   5.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.593 total time=   5.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.582 total time=   4.9s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.522 total time=   4.8s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.615 total time=   1.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.571 total time=   1.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.621 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.582 total time=   1.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.582 total time=   1.4s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.577 total time=   2.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.571 total time=   2.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.621 total time=   2.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.621 total time=   2.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.621 total time=   2.3s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.577 total time=   3.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.560 total time=   4.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.632 total time=   3.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.599 total time=   3.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.604 total time=   3.6s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.582 total time=   4.9s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.555 total time=   5.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.626 total time=   4.8s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.610 total time=   4.9s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.588 total time=   5.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.582 total time=   1.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.571 total time=   1.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.637 total time=   1.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.610 total time=   1.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.621 total time=   1.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.577 total time=   2.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.555 total time=   2.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.621 total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.604 total time=   2.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.593 total time=   2.5s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.560 total time=   3.8s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.544 total time=   3.8s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.593 total time=   3.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.571 total time=   4.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.588 total time=   4.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.538 total time=   5.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.533 total time=   4.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.571 total time=   4.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.571 total time=   5.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.577 total time=   5.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.527 total time=   1.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.516 total time=   1.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.582 total time=   1.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.549 total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.533 total time=   1.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.516 total time=   2.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.505 total time=   2.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.599 total time=   2.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.610 total time=   2.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.527 total time=   2.6s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.500 total time=   3.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.500 total time=   4.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.593 total time=   3.4s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.593 total time=   3.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.527 total time=   3.4s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.500 total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.495 total time=   4.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.610 total time=   4.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.593 total time=   4.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.522 total time=   4.5s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.544 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.544 total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.577 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.560 total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=100;, score=0.538 total time=   1.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.527 total time=   2.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.527 total time=   2.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.604 total time=   2.7s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.571 total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=200;, score=0.527 total time=   2.9s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.533 total time=   3.7s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.527 total time=   3.8s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.599 total time=   4.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.582 total time=   3.8s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=300;, score=0.533 total time=   3.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.527 total time=   5.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.505 total time=   5.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.593 total time=   5.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.593 total time=   4.9s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, n_estimators=400;, score=0.522 total time=   5.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.615 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.571 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.621 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.582 total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=100;, score=0.582 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.577 total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.571 total time=   2.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.626 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.615 total time=   2.6s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=200;, score=0.621 total time=   2.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.577 total time=   3.8s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.560 total time=   3.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.632 total time=   3.8s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.599 total time=   3.9s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=300;, score=0.604 total time=   3.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.582 total time=   5.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.555 total time=   5.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.626 total time=   5.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.610 total time=   5.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=deviance, n_estimators=400;, score=0.588 total time=   5.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.582 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.566 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.632 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.610 total time=   1.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=100;, score=0.621 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.577 total time=   2.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.555 total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.621 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.599 total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=200;, score=0.593 total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.555 total time=   3.8s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.544 total time=   3.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.599 total time=   3.8s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.571 total time=   3.7s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=300;, score=0.588 total time=   3.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.538 total time=   4.9s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.533 total time=   5.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.577 total time=   4.9s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.571 total time=   5.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=deviance, n_estimators=400;, score=0.588 total time=   4.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.02, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=logloss, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.527 total time=   1.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.516 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.582 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.604 total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=100;, score=0.527 total time=   1.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.500 total time=   2.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.505 total time=   2.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.604 total time=   2.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.599 total time=   2.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=200;, score=0.527 total time=   2.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.505 total time=   3.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.495 total time=   3.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.588 total time=   3.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.599 total time=   3.7s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=300;, score=0.527 total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.500 total time=   5.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.500 total time=   4.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.599 total time=   4.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.593 total time=   4.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, n_estimators=400;, score=0.516 total time=   4.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=exponential, n_estimators=400;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'learning_rate': [0.1, 0.01, 0.02, 0.2],\n",
       "                         'loss': ['logloss', 'deviance', 'exponential'],\n",
       "                         'n_estimators': [100, 200, 300, 400]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9f6a6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.02,\n",
       " 'loss': 'deviance',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84830b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(criterion = 'friedman_mse',learning_rate=0.02,loss='deviance',n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eae03428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.02)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23c510bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbd2dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d914384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5857461024498887\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  17   4   1   0]\n",
      " [  1   1 133  52   0   1]\n",
      " [  0   1  56 110   9   0]\n",
      " [  0   0   3  30  20   0]\n",
      " [  0   0   0   4   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.63      0.71      0.67       188\n",
      "           6       0.55      0.62      0.59       176\n",
      "           7       0.61      0.38      0.47        53\n",
      "           8       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.59       449\n",
      "   macro avg       0.30      0.28      0.29       449\n",
      "weighted avg       0.55      0.59      0.56       449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674300f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
